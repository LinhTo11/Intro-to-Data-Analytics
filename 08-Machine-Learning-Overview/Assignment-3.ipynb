{"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.9.5 64-bit ('base': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"colab":{"name":"Assignment-3.ipynb","provenance":[],"collapsed_sections":[]},"interpreter":{"hash":"b20e4dd35a95a1f0a413df6f9e0809e8249ac6991d40e3f9a5d7e657ecdd8861"}},"cells":[{"cell_type":"markdown","source":["# Assignment 3\r\n","\r\n","## Question 1 (12 points)\r\n","Using the [Framingham Heart Study dataset](https://github.com/soltaniehha/Intro-to-Data-Analytics/blob/main/data/AnalyticsEdge-Datasets/Framingham.csv) create a **logistic regression** model to predict whether a patient will develop heart desease in 10 years or not.\r\n","\r\n","Follow the steps outlined in the [Classification notebook](https://github.com/soltaniehha/Intro-to-Data-Analytics/blob/main/08-Machine-Learning-Overview/03-Classification.ipynb):\r\n","* Preprocessing: deleting columns with no predictive power/handling missing values\r\n","* Preprocessing: handle categorical variables, if any\r\n","* Create feature matrix and target vector. Our target variable is `TenYearCHD`\r\n","* Split the data randomly into train and test with a 70-30 split (use `random_state=780`)\r\n","* Instantiate and fit a logistic regression model\r\n","* Make predictions and find the overall accuracy, sensitivity, and specificity on your test set\r\n","\r\n","**Note:** We have seen this dataset during the discussion on the Framingham Heart Study from Analytics Edge.\r\n","\r\n","## Question 2 (8 points)\r\n","Open ended - Do further data exploration and create new variables when possible (feature engineering). Show your discovery process using plots and summaries. \r\n","* How does the model performance change by adding new variables or potentially removing some of the less important ones? \r\n","* How does the model performance change by trying different classification models?\r\n","\r\n","---\r\n","\r\n","### Upload your .ipynb file to Questrom Tools\r\n","\r\n","A potential issue is to download the notebook before it was fully saved. To avoid this, follow these steps: \r\n","1. go to Runtime (in the menu) and hit \"Restart and run all...\" \r\n","2. after the notebook is fully run, save it and then download your .ipynb to your computer \r\n","3. upload it back to your Drive and open it with Colab to ensure all of your recent changes are there \r\n","4. upload the originally downloaded file to Questrom Tools.\r\n","\r\n","---\r\n","\r\n","The data has been loaded in the following cell:"],"metadata":{"id":"X5KJmEfIJWKH"}},{"cell_type":"code","execution_count":1,"source":["import pandas as pd\r\n","\r\n","df = pd.read_csv('https://raw.githubusercontent.com/soltaniehha/Intro-to-Data-Analytics/master/data/AnalyticsEdge-Datasets/Framingham.csv')\r\n","df.head(3)"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>male</th>\n","      <th>age</th>\n","      <th>education</th>\n","      <th>currentSmoker</th>\n","      <th>cigsPerDay</th>\n","      <th>BPMeds</th>\n","      <th>prevalentStroke</th>\n","      <th>prevalentHyp</th>\n","      <th>diabetes</th>\n","      <th>totChol</th>\n","      <th>sysBP</th>\n","      <th>diaBP</th>\n","      <th>BMI</th>\n","      <th>heartRate</th>\n","      <th>glucose</th>\n","      <th>TenYearCHD</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>39</td>\n","      <td>4.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>195.0</td>\n","      <td>106.0</td>\n","      <td>70.0</td>\n","      <td>26.97</td>\n","      <td>80.0</td>\n","      <td>77.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>46</td>\n","      <td>2.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>250.0</td>\n","      <td>121.0</td>\n","      <td>81.0</td>\n","      <td>28.73</td>\n","      <td>95.0</td>\n","      <td>76.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>48</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>20.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>245.0</td>\n","      <td>127.5</td>\n","      <td>80.0</td>\n","      <td>25.34</td>\n","      <td>75.0</td>\n","      <td>70.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n","0     1   39        4.0              0         0.0     0.0                0   \n","1     0   46        2.0              0         0.0     0.0                0   \n","2     1   48        1.0              1        20.0     0.0                0   \n","\n","   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n","0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n","1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n","2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n","\n","   TenYearCHD  \n","0           0  \n","1           0  \n","2           0  "]},"metadata":{},"execution_count":1}],"metadata":{"id":"bTC6KZksJWKJ","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1632972402379,"user_tz":240,"elapsed":147,"user":{"displayName":"Mohammad Soltanieh Ha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHn5A5nCXb4FsIfIBdin6XTbj6u54lww1hF6ECkT8=s64","userId":"12308918870841825745"}},"outputId":"00f76794-42a2-42fb-9ba1-b4b66de89fce"}},{"cell_type":"markdown","source":["# Question 1"],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["# Preprocessing: deleting columns with no predictive power/handling missing values\r\n","# I'm gonna delete 6 cols BPMeds, prevelent Stroke, prevalent Hyp, sysBP, diaBP: because I don't have any domain knowledge\r\n","df.drop(['BPMeds', 'prevalentStroke', 'prevalentHyp', 'sysBP', 'diaBP'], axis = 1, inplace = True)\r\n","\r\n","\r\n","# Using DataFrame.drop\r\n","# df.drop(df.columns[[1, 2]], axis=1, inplace=True)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["#dropping nulls so hard right now\r\n","\r\n","df.dropna(axis = 0, how = 'any', inplace = True)\r\n","df.isnull().sum()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["male             0\n","age              0\n","education        0\n","currentSmoker    0\n","cigsPerDay       0\n","diabetes         0\n","totChol          0\n","BMI              0\n","heartRate        0\n","glucose          0\n","TenYearCHD       0\n","dtype: int64"]},"metadata":{},"execution_count":3}],"metadata":{}},{"cell_type":"code","execution_count":4,"source":["#Preprocessing: handle categorical variables, if any\r\n","#Don't have any"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":5,"source":["# Create feature matrix and target vector. Our target variable is `TenYearCHD`\r\n","\r\n","X = df.drop('TenYearCHD', axis = 1)\r\n","y = df['TenYearCHD']\r\n","\r\n","y.shape"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3709,)"]},"metadata":{},"execution_count":5}],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["# Split the data randomly into train and test with a 70-30 split (use `random_state=780`)\r\n","\r\n","\r\n","\r\n","# !pip install sklearn -q\r\n","from sklearn import linear_model\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 780, stratify= y)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["#* Instantiate and fit a logistic regression model\r\n","\r\n","model = linear_model.LogisticRegression(max_iter=2000)\r\n","model.fit(X_train, y_train)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(max_iter=2000)"]},"metadata":{},"execution_count":7}],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["#Make predictions \r\n","\r\n","y_hat = model.predict(X_test)\r\n","y_hat.shape"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1113,)"]},"metadata":{},"execution_count":8}],"metadata":{}},{"cell_type":"code","execution_count":9,"source":["y_test.shape"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1113,)"]},"metadata":{},"execution_count":9}],"metadata":{}},{"cell_type":"code","execution_count":15,"source":["# Find the overall accuracy, sensitivity, and specificity on your test set\r\n","from sklearn.metrics import accuracy_score\r\n","accuracy = accuracy_score(y_test, y_hat)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["print(\"Our model is\", round(sum(y_test == y_hat)/len(y_hat),2) * 100, \"% accurate!\")\r\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["Our model is 85.0 % accurate!\n"]}],"metadata":{}},{"cell_type":"markdown","source":["# Question 2 "],"metadata":{}},{"cell_type":"markdown","source":["## How does the model performance change by adding new variables or potentially removing some of the less important ones? \r\n"],"metadata":{}},{"cell_type":"code","execution_count":12,"source":["# OK let's add all the variables to see how it goes haha\r\n","\r\n","df = pd.read_csv('https://raw.githubusercontent.com/soltaniehha/Intro-to-Data-Analytics/master/data/AnalyticsEdge-Datasets/Framingham.csv')\r\n","df.dropna(axis = 0, how = 'any', inplace = True)\r\n","df.isnull().sum()\r\n","\r\n","X = df.drop('TenYearCHD', axis = 1)\r\n","y = df['TenYearCHD']\r\n","\r\n","Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.3, random_state = 780, stratify= y)\r\n","\r\n","model.fit(Xtrain, ytrain)\r\n","\r\n","yhat = model.predict(Xtest)\r\n","yhat.shape"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1098,)"]},"metadata":{},"execution_count":12}],"metadata":{}},{"cell_type":"code","execution_count":13,"source":["from sklearn.metrics import accuracy_score\r\n","adding_all_accuracy = accuracy_score(ytest, yhat)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":16,"source":["adding_all_accuracy - accuracy "],"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.005223906244629983"]},"metadata":{},"execution_count":16}],"metadata":{}},{"cell_type":"code","execution_count":14,"source":["print(\"Our model is\", round(sum(ytest == yhat)/len(yhat),2) * 100, \"% accurate!\")\r\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["Our model is 85.0 % accurate!\n"]}],"metadata":{}},{"cell_type":"markdown","source":["Huh it's literally the same"],"metadata":{}},{"cell_type":"code","execution_count":17,"source":["print(\"The fit all variables model improves about\", (adding_all_accuracy - accuracy) * 100, \"%\" )"],"outputs":[{"output_type":"stream","name":"stdout","text":["The fit all variables model improves about 0.5223906244629983 %\n"]}],"metadata":{}},{"cell_type":"markdown","source":["## How does the model performance change by trying different classification models?"],"metadata":{}},{"cell_type":"code","execution_count":22,"source":["from sklearn.naive_bayes import GaussianNB\r\n","\r\n","Gau_model = GaussianNB()\r\n","\r\n","Gau_model.fit(Xtrain, ytrain)\r\n","\r\n","y_hat_gau = Gau_model.predict(Xtest)\r\n","\r\n","print(\"Our Gaussian model is\", round(sum(ytest == y_hat_gau)/len(y_hat_gau),2), \"accurate!\")\r\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["Our Gaussian model is 0.82 accurate!\n"]}],"metadata":{}}]}